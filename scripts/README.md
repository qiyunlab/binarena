# Scripts

This directory hosts multiple Python scripts for analysis and formatting outside the BinaRena main program. They are useful for preparing the input files for BinaRena. Each script has a command-line interface when you execute them. This page describes their typical usages.


## Contents

- [Basic sequence information](#basic-sequence-information)
- [Contig annotation parsing](#contig-annotation-parsing)
- [_k_-mer frequencies](#k-mer-frequencies)
- [Dimensionality reduction](#dimensionality-reduction)
- [Lineage string conversion](#lineage-string-conversion)
- [Kraken taxonomic profile](#kraken-taxonomic-profile)
- [CheckM marker genes](#checkm-marker-genes)


## Basic sequence information

The script [`sequence_basics.py`](sequence_basics.py) obtains length, GC content, and coverage (if applicable) from contig sequences (multi-FASTA format). Example:

```bash
sequence_basics.py -i contigs.fna -o basic.tsv
```

When the input file was generated by [SPAdes](https://github.com/ablab/spades) or [MEGAHIT](https://github.com/voutcn/megahit), the script will automatically recognize and extract the coverage values from the sequence titles.

- [Note] This "coverage" is not the same as one would get from mapping reads to contigs.

Alternatively, one can "pipe" the input and output files. This mechanism is available for most scripts here.

```bash
zcat contigs.fna.gz | sequence_basics.py | gzip > basic.tsv.gz
```

One can specify a minimum contig length threshold (say 1 kb):

```bash
sequence_basics.py -i contigs.fna -l 1000 -o basic.tsv
```


## Contig annotation parsing

[`orf_to_contig.py`](orf_to_contig.py) converts an ORF-to-feature mapping into a contig-to-feature(s) mapping.

```bash
orf_to_contig.py orf-to-gene.map > ctg-to-genes.map
```

The resulting mapping file can be appended to a dataset as a "feature set" column for BinaRena.


## _k_-mer frequencies

[`count_kmers.py`](count_kmers.py) calculates _k_-mer frequencies of contig sequences. For example:

```bash
count_kmers.py -i contigs.fna -k 4 -o tetramers.tsv
```

This is an exact _k_-mer counter. The frequencies of all _k_-mers will be reported. Both forward and reverse strands are considered. _k_-mers with non-ACGT characters are discarded. Upper and lower cases are both fine.

The output is a tab-separated table with rows as sequence identifiers and columns as all possible _k_-mers (including unobserved ones).

- [Note] This _k_-mer counter is optimized for small _k_-values (_k_ = 4, 5, 6...) and many sequences, which are typical for the task of contig binning. It is not efficient for large _k_-values (e.g., _k_ = 35). 

- [Note] The output file may be large, especially for relatively big _k_'s. One may consider piping the output to a downstream application (see below).


## Dimensionality reduction

[`reduce_dimension.py`](reduce_dimension.py) is a pipeline for reducing the dimensionality of certain contig properties (such as _k_-mer frequencies and per-sample coverages) such that they can be visualized in a low-dimension space (e.g., a 2D or 3D scatter plot). Three commonly used dimensionality reduction methods are implemented, including principal component analysis ([PCA](https://en.wikipedia.org/wiki/Principal_component_analysis)), t-distributed stochastic neighbor embedding ([t-SNE](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding)) and uniform manifold approximation and projection ([UMAP](https://en.wikipedia.org/wiki/Nonlinear_dimensionality_reduction#Uniform_manifold_approximation_and_projection)).

This script requires Python libraries [scikit-bio](http://scikit-bio.org/), [scikit-learn](https://scikit-learn.org/stable/), and [umap-learn](https://umap-learn.readthedocs.io/en/latest/). You need to install them first:

```bash
conda install -c conda-forge scikit-bio scikit-learn umap-learn
```

Then you can run the script. Example:

```bash
reduce_dimension.py -i kmer_freqs.tsv --pca --tsne --umap -o output
```

The input is a table (TSV), with rows as contigs and columns as properties. The output files will be `output.pca.tsv`, `output.tsne.tsv`, `output.umap.tsv`.

You may connect [`count_kmers.py`](count_kmers.py) and `reduce_dimension.py` using a pipe, such that the intermediate _k_-mer frequencies file (which is large) can be skipped. This is efficient for data-intensive analyses. Example:

```bash
count_kmers.py -i contigs.fna -k 5 | reduce_dimension.py --pca --tsne --umap -o output
```

Details of the pipeline:

1. Add a pseudocount (default: 1) to any feature that has zeros.
2. Perform centered log-ratio transform ([CLR](https://en.wikipedia.org/wiki/Compositional_data#Center_logratio_transform)) on each feature.
3. Perform PCA on the transformed data.
4. If there are >200 features, perform PCA to reduce the transformed data to 50 principal components.
5. Perform t-SNE on the reduced data.
6. Perform UMAP on the reduced data.


## Lineage string conversion

If you have a contig ID to lineage string mapping file, like:

```
ctg1 <tab> d__Bacteria; p__Proteobacteria; c__Gammaproteobacteria; o__Enterobacterales; f__Enterobacteriaceae; g__Escherichia; s__Escherichia coli
```

Then you can use [`lineage_to_table.py`](lineage_to_table.py) to convert it to a table, with each column as a taxonomic rank:

```bash
lineage_to_table.py lineage.map > taxonomy.tsv
```

The output file will be like:

| ID | domain | phylum | class | order | family | genus | species |
| --- | --- | --- | --- | --- | --- | --- | --- |
| ctg1 | Bacteria | Proteobacteria | Gammaproteobacteria | Enterobacterales | Enterobacteriaceae | Escherichia | Escherichia coli |


## Kraken taxonomic profile

[Kraken2](https://ccb.jhu.edu/software/kraken2/) is a widely used tool for assigning taxonomy to contig sequences. You can run Kraken2 like this (see the [Kraken2 manual](https://github.com/DerrickWood/kraken2/wiki/Manual#classification) for more details):

```bash
kraken2 --db db_dir contigs.fna --output kraken.output --report kraken.report
```

The two output files, `kraken.output` is a mapping of contig IDs to taxonomy IDs; `kraken.report` is a hierarchical taxonomic profile of the sample.

You can use [`kraken_to_table.py`](kraken_to_table.py) to convert the result into a table, with rows as contig IDs and columns as taxonomic ranks:

```bash
kraken_to_table.py -i kraken.output -r kraken.report -o taxonomy.tsv
```

If you don't have the Kraken report files, but have the original [NCBI taxdump](https://ftp.ncbi.nih.gov/pub/taxonomy/taxdump.tar.gz), you can do this instead (the directory `taxdump_dir` should contain `nodes.dmp` and `names.dmp`):

```bash
kraken_to_table.py -i kraken.output -d taxdump_dir -o taxonomy.tsv
```


## CheckM marker genes

[CheckM] is the standard tool for evaluating bin qualities. It calculates **completeness** and **contamination** (redundancy) of each bin by assessing the distribution of lineage-specific marker genes. The scripts [checkm_marker_map.py](checkm_marker_map.py) and [checkm_marker_list.py](checkm_marker_list.py) can reformat the CheckM output files such that the can enable BinaRena to calculate completeness and redundancy in real time.

Step 1. Have the entire set of contigs (unbinned) in a multi-FASTA file `input/contigs.fna`.

- [Note] This is slightly different from the typical use of CheckM, which should run on individual bins. You can do that too, if you are only interested in binned contigs.

Step 2. Determine which target taxon should be analyzed. For example, domain Bacteria (which is quite generic) is used in the following example. (A list of available taxa can be found using `checkm taxon_list`.)

Step 3. Run CheckM [taxonomic-specific workflow](https://github.com/Ecogenomics/CheckM/wiki/Workflows#taxonomic-specific-workflow) as recommended:

```bash
checkm taxonomy_wf domain Bacteria input output
```

Step 4. Convert the CheckM output into a contig-to-markers map using [checkm_marker_map.py](checkm_marker_map.py):

```bash
python checkm_marker_map.py output/storage/marker_gene_stats.tsv > Bacteria.map
```

The output file `Bacteria.map` can be imported into BinaRena as a "feature set" field.

Step 5. Convert a CheckM marker set definition into a marker list using [checkm_marker_list.py](checkm_marker_list.py):

```bash
python checkm_marker_list.py output/Bacteria.ms > Bacteria.lst
```

The output file `Bacteria.lst` can be imported into BinaRena as a feature group membership list.

Step 6. You can now use the "feature group" menu item to calculate **completeness** and **redundancy** (contamination) scores of selection contigs on the fly! See [details](..#completeness--redundancy-calculation).

- [Tip] You may load multiple marker gene sets into BinaRena and calculate using each of them.

- [Note] The output values are analogous to CheckM's completeness and contamination scores, and they can be intepreted in a similar way. However there is one difference: CheckM considers the **collocation** of marker genes when calculating these metrics. BinaRena does not, however, and the output values are based on a plain list of features. Therefore the results may be different, although they are highly correlated.

- [Note] Also, BinaRena can only analyze specified marker gene sets (in this example: Bacteria), unlike CheckM's `lineage_wf` which can automatically determine the lineage of each bin and use the corresponding lineage-specific marker gene set for that bin.
